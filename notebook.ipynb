{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scaled Dot Product Attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    # Calculate the dot product, QK_transpose\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    # Get the scale factor\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    # Apply the scale factor to the dot product\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    # Apply masking when it is requiered\n",
    "    if mask is not None:\n",
    "        scaled_product += (mask * -1e9)\n",
    "    # dot product with Values\n",
    "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
    "\n",
    "    return attention\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiHeadAttention class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "\n",
    "    def __init__(self, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        assert self.d_model % self.n_heads == 0\n",
    "        # Calculate the dimension of every head or projection\n",
    "        self.d_head = self.d_model // self.n_heads\n",
    "        # Set the weight matrices for Q, K and V\n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "        # Set the weight matrix for the output of the multi-head attention W0\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "\n",
    "    def split_proj(self, inputs, batch_size):  # inputs: (batch_size, seq_length, d_model)\n",
    "        # Set the dimension of the projections\n",
    "        shape = (batch_size,\n",
    "                 -1,\n",
    "                 self.n_heads,\n",
    "                 self.d_head)\n",
    "        # Split the input vectors\n",
    "        # (batch_size, seq_length, nb_proj, d_proj)\n",
    "        splited_inputs = tf.reshape(inputs, shape=shape)\n",
    "        # (batch_size, nb_proj, seq_length, d_proj)\n",
    "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        # Set the Query, Key and Value matrices\n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.value_lin(values)\n",
    "        # Split Q, K y V between the heads or projections\n",
    "        queries = self.split_proj(queries, batch_size)\n",
    "        keys = self.split_proj(keys, batch_size)\n",
    "        values = self.split_proj(values, batch_size)\n",
    "        # Apply the scaled dot product\n",
    "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
    "        # Get the attention scores\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        # Concat the h heads or projections\n",
    "        concat_attention = tf.reshape(attention,\n",
    "                                      shape=(batch_size, -1, self.d_model))\n",
    "        # Apply W0 to get the output of the multi-head attention\n",
    "        outputs = self.final_lin(concat_attention)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Positional encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def get_angles(self, pos, i, d_model):  # pos: (seq_length, 1) i: (1, d_model)\n",
    "        angles = 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
    "        return pos * angles  # (seq_length, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # input shape batch_size, seq_length, d_model\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "        # Calculate the angles given the input\n",
    "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
    "                                 np.arange(d_model)[np.newaxis, :],\n",
    "                                 d_model)\n",
    "        # Calculate the positional encodings\n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
    "        # Expand the encodings with a new dimension\n",
    "        pos_encoding = angles[np.newaxis, ...]\n",
    "\n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder Layer & Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, FFN_units, n_heads, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # Hidden units of the feed forward component\n",
    "        self.FFN_units = FFN_units\n",
    "        # Set the number of projectios or heads\n",
    "        self.n_heads = n_heads\n",
    "        # Dropout rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        # Build the multihead layer\n",
    "        self.multi_head_attention = MultiHeadAttention(self.n_heads)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
    "        # Layer Normalization\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        # Fully connected feed forward layer\n",
    "        self.ffn1_relu = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
    "        self.ffn2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
    "        # Layer normalization\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, mask, training):\n",
    "        # Forward pass of the multi-head attention\n",
    "        attention = self.multi_head_attention(inputs,\n",
    "                                              inputs,\n",
    "                                              inputs,\n",
    "                                              mask)\n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        # Call to the residual connection and layer normalization\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        # Call to the FC layer\n",
    "        outputs = self.ffn1_relu(attention)\n",
    "        outputs = self.ffn2(outputs)\n",
    "        outputs = self.dropout_2(outputs, training=training)\n",
    "        # Call to residual connection and the layer normalization\n",
    "        outputs = self.norm_2(outputs + attention)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Encoder(layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 FFN_units,\n",
    "                 n_heads,\n",
    "                 dropout_rate,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"encoder\"):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        # The embedding layer\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        # Positional encoding layer\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        # Stack of n layers of multi-head attention and FC\n",
    "        self.enc_layers = [EncoderLayer(FFN_units,\n",
    "                                        n_heads,\n",
    "                                        dropout_rate)\n",
    "                           for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, mask, training):\n",
    "        # Get the embedding vectors\n",
    "        outputs = self.embedding(inputs)\n",
    "        # Scale the embeddings by sqrt of d_model\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        # Positional encodding\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        # Call the stacked layers\n",
    "        for i in range(self.n_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder Layer & Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, FFN_units, n_heads, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "\n",
    "        # Self multi head attention, causal attention\n",
    "        self.multi_head_causal_attention = MultiHeadAttention(self.n_heads)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Multi head attention, encoder-decoder attention\n",
    "        self.multi_head_enc_dec_attention = MultiHeadAttention(self.n_heads)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Feed foward\n",
    "        self.ffn1_relu = layers.Dense(units=self.FFN_units,\n",
    "                                      activation=\"relu\")\n",
    "        self.ffn2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        # Call the masked causal attention\n",
    "        attention = self.multi_head_causal_attention(inputs,\n",
    "                                                     inputs,\n",
    "                                                     inputs,\n",
    "                                                     mask_1)\n",
    "        attention = self.dropout_1(attention, training)\n",
    "        # Residual connection and layer normalization\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        # Call the encoder-decoder attention\n",
    "        attention_2 = self.multi_head_enc_dec_attention(attention,\n",
    "                                                        enc_outputs,\n",
    "                                                        enc_outputs,\n",
    "                                                        mask_2)\n",
    "        attention_2 = self.dropout_2(attention_2, training)\n",
    "        # Residual connection and layer normalization\n",
    "        attention_2 = self.norm_2(attention_2 + attention)\n",
    "        # Call the Feed forward\n",
    "        outputs = self.ffn1_relu(attention_2)\n",
    "        outputs = self.ffn2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        # Residual connection and layer normalization\n",
    "        outputs = self.norm_3(outputs + attention_2)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Decoder(layers.Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 FFN_units,\n",
    "                 n_heads,\n",
    "                 dropout_rate,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"decoder\"):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        # Embedding layer\n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        # Positional encoding layer\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        # Stacked layers of multi-head attention and feed forward\n",
    "        self.dec_layers = [DecoderLayer(FFN_units,\n",
    "                                        n_heads,\n",
    "                                        dropout_rate)\n",
    "                           for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        # Get the embedding vectors\n",
    "        outputs = self.embedding(inputs)\n",
    "        # Scale by sqrt of d_model\n",
    "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        # Positional encodding\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        # Call the stacked layers\n",
    "        for i in range(self.n_layers):\n",
    "            outputs = self.dec_layers[i](outputs,\n",
    "                                         enc_outputs,\n",
    "                                         mask_1,\n",
    "                                         mask_2,\n",
    "                                         training)\n",
    "\n",
    "        return outputs\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}